{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "O5-ur_FzWw3c"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # Disable TF debugg log\n",
        "\n",
        "# Auxiliar imports\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "\n",
        "# Model auxiliar imports\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "import keras_tuner\n",
        "\n",
        "# Model imports\n",
        "from tensorflow.keras.models import load_model, Sequential  # Load saved model\n",
        "from tensorflow.keras.optimizers import Adam  # Optimizer\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "# from tensorflow.keras.applications import Res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Wb96MjUnMU8H"
      },
      "outputs": [],
      "source": [
        "def getSetDir(set=\"train\"):\n",
        "    dirs = [f\"./../dataset/archive/dataset/{set}/\"]\n",
        "    return dirs\n",
        "\n",
        "\n",
        "# Load dataset training data\n",
        "def loadData(set=\"train\", verbose=False, size=30):\n",
        "    data = []\n",
        "    labels = []\n",
        "\n",
        "    for dir in getSetDir(set):\n",
        "        for subdir in os.listdir(dir):\n",
        "            for img in os.listdir(dir + subdir)[0:size-1]:\n",
        "                arrayLikeImage = load_img(dir + subdir + \"/\" + img, target_size=(300, 300))\n",
        "                # arrayLikeImage = img_to_array(arrayLikeImage)\n",
        "                data.append(arrayLikeImage)\n",
        "                labels.append(subdir)\n",
        "            if verbose:\n",
        "                print(f\"Done with [{subdir}] images.\")\n",
        "\n",
        "    return data, labels\n",
        "\n",
        "\n",
        "trainData, trainLabels = loadData(\"train\", size=100)\n",
        "testData, testLabels = loadData(\"test\", size=10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "xS0hBbfubUDd"
      },
      "outputs": [],
      "source": [
        "# One-Hot Encode dataset\n",
        "lb = LabelBinarizer()\n",
        "trainLabels = lb.fit_transform(trainLabels)\n",
        "# trainLabels = to_categorical(trainLabels)  # Turn each label into a binary array\n",
        "\n",
        "testLabels = lb.fit_transform(testLabels)\n",
        "# testLabels = to_categorical(testLabels)  # Turn each label into a binary array\n",
        "\n",
        "trainData = np.array(trainData, dtype=\"float32\")\n",
        "trainLabels = np.array(trainLabels)\n",
        "testData = np.array(testData, dtype=\"float32\")\n",
        "testLabels = np.array(testLabels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "JBGkbyB-WnrL"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "\n",
        "# Create Model\n",
        "kernelWindow = (3, 3)\n",
        "# model.add(Conv2D(32, kernel_size=kernelWindow[0], activation=\"relu\", input_shape=trainData[0].shape))\n",
        "# model.add(MaxPooling2D(pool_size=kernelWindow))\n",
        "model.add(Conv2D(32, kernel_size=kernelWindow[0], activation=\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=kernelWindow))\n",
        "model.add(Flatten(name=\"flattten\"))\n",
        "model.add(Dense(128, activation=\"relu\"))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(26, activation=\"softmax\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "vw09VNZ-XbNe"
      },
      "outputs": [],
      "source": [
        "# Compile the model\n",
        "STEP_LEN = 1e-6\n",
        "EPOCHS = 3\n",
        "BATCH_SIZE = 30\n",
        "opt = Adam(learning_rate=STEP_LEN, decay=STEP_LEN / EPOCHS)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "SS401NDOd1Ni"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "85/85 [==============================] - 9s 95ms/step - loss: 3.2525 - accuracy: 0.0404 - val_loss: 3.3383 - val_accuracy: 0.0381\n",
            "Epoch 2/3\n",
            "85/85 [==============================] - 8s 90ms/step - loss: 3.2520 - accuracy: 0.0409 - val_loss: 3.3383 - val_accuracy: 0.0381\n",
            "Epoch 3/3\n",
            "85/85 [==============================] - 8s 95ms/step - loss: 3.2475 - accuracy: 0.0417 - val_loss: 3.3383 - val_accuracy: 0.0381\n"
          ]
        }
      ],
      "source": [
        "# Train\n",
        "T = model.fit(\n",
        "    x=trainData,\n",
        "    y=trainLabels,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    steps_per_epoch=len(trainData) // BATCH_SIZE,\n",
        "    validation_data=(testData, testLabels),\n",
        "    validation_steps=len(testData) // BATCH_SIZE,\n",
        "    epochs=EPOCHS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1U31_HSrYnmD",
        "outputId": "a700458e-3bc4-439e-ae40-ea2f2660c7f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "- [INFO] evaluating network...\n",
            "8/8 [==============================] - 1s 74ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           A       0.00      0.00      0.00         9\n",
            "           B       0.00      0.00      0.00         9\n",
            "           C       0.00      0.00      0.00         9\n",
            "           D       0.00      0.00      0.00         9\n",
            "           E       0.00      0.00      0.00         9\n",
            "           F       0.00      0.00      0.00         9\n",
            "           G       0.00      0.00      0.00         9\n",
            "           H       0.00      0.00      0.00         9\n",
            "           I       0.00      0.00      0.00         9\n",
            "           J       0.00      0.00      0.00         9\n",
            "           K       0.00      0.00      0.00         9\n",
            "           L       0.00      0.00      0.00         9\n",
            "           M       0.00      0.00      0.00         9\n",
            "           N       0.00      0.00      0.00         9\n",
            "           O       0.00      0.00      0.00         9\n",
            "           P       0.00      0.00      0.00         9\n",
            "           Q       0.00      0.00      0.00         9\n",
            "           R       0.00      0.00      0.00         9\n",
            "           S       0.00      0.00      0.00         9\n",
            "           T       0.00      0.00      0.00         9\n",
            "           U       0.00      0.00      0.00         9\n",
            "           V       0.00      0.00      0.00         9\n",
            "           W       0.04      0.89      0.07         9\n",
            "           X       0.00      0.00      0.00         9\n",
            "           Y       0.00      0.00      0.00         9\n",
            "           Z       0.00      0.00      0.00         9\n",
            "\n",
            "    accuracy                           0.03       234\n",
            "   macro avg       0.00      0.03      0.00       234\n",
            "weighted avg       0.00      0.03      0.00       234\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/vinicius-verona/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/home/vinicius-verona/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/home/vinicius-verona/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "print(\"- [INFO] evaluating network...\")\n",
        "predictedIdxs = model.predict(testData, batch_size = BATCH_SIZE)\n",
        "predictedIdxs = np.argmax(predictedIdxs, axis=1)\n",
        "print(classification_report(testLabels.argmax(axis = 1), predictedIdxs, target_names = lb.classes_))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.6 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
